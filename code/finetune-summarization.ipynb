{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10275534,"sourceType":"datasetVersion","datasetId":6191065}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\nds = load_dataset(\"EdinburghNLP/xsum\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-06T02:11:59.520592Z","iopub.execute_input":"2024-12-06T02:11:59.521192Z","iopub.status.idle":"2024-12-06T02:12:08.894161Z","shell.execute_reply.started":"2024-12-06T02:11:59.521150Z","shell.execute_reply":"2024-12-06T02:12:08.893272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"small_train_dataset = ds[\"train\"].select(range(100000))\nsmall_eval_dataset = ds[\"validation\"].select(range(5000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T02:12:12.369691Z","iopub.execute_input":"2024-12-06T02:12:12.370054Z","iopub.status.idle":"2024-12-06T02:12:12.378674Z","shell.execute_reply.started":"2024-12-06T02:12:12.370020Z","shell.execute_reply":"2024-12-06T02:12:12.377913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T02:12:16.968524Z","iopub.execute_input":"2024-12-06T02:12:16.969499Z","iopub.status.idle":"2024-12-06T02:12:17.907597Z","shell.execute_reply.started":"2024-12-06T02:12:16.969457Z","shell.execute_reply":"2024-12-06T02:12:17.906914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.login(key=\"5aebd9bb882a1970238cc8743aa4de990e61d2c7\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T02:12:20.140340Z","iopub.execute_input":"2024-12-06T02:12:20.140668Z","iopub.status.idle":"2024-12-06T02:12:21.159584Z","shell.execute_reply.started":"2024-12-06T02:12:20.140639Z","shell.execute_reply":"2024-12-06T02:12:21.158844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"hchang/t5-small-finetuned-xsum\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"hchang/t5-small-finetuned-xsum\")\n\ndef preprocess_function(examples):\n    inputs = examples[\"document\"]\n    targets = examples[\"summary\"]\n    model_inputs = tokenizer(inputs, max_length=1024, padding=\"max_length\", truncation=True)\n    \n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=128, padding=\"max_length\", truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntrain_tokenized_datasets = small_train_dataset.map(preprocess_function, batched=True)\neval_tokenized_datasets = small_eval_dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T14:42:38.104007Z","iopub.execute_input":"2024-11-29T14:42:38.104534Z","iopub.status.idle":"2024-11-29T14:42:38.108995Z","shell.execute_reply.started":"2024-11-29T14:42:38.104493Z","shell.execute_reply":"2024-11-29T14:42:38.108199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",             # Directory for model checkpoints\n    evaluation_strategy=\"epoch\",       # Evaluate after every epoch\n    learning_rate=1e-5,                # Initial learning rate\n    per_device_train_batch_size=4,     # Training batch size per device\n    per_device_eval_batch_size=4,      # Evaluation batch size per device\n    weight_decay=0.01,                 # Weight decay for optimizer\n    save_total_limit=3,                # Max number of checkpoints to save\n    num_train_epochs=2,                # Number of training epochs\n    predict_with_generate=True,        # Use the model's `generate` for evaluation\n    logging_dir=\"./logs\",              # Directory for logs\n    logging_steps=10,                  # Log every 10 steps\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T14:42:38.110206Z","iopub.execute_input":"2024-11-29T14:42:38.110653Z","iopub.status.idle":"2024-11-29T14:42:38.121504Z","shell.execute_reply.started":"2024-11-29T14:42:38.110615Z","shell.execute_reply":"2024-11-29T14:42:38.120842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, AutoModelForSeq2SeqLM\nfrom transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_tokenized_datasets,\n    eval_dataset=eval_tokenized_datasets,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T14:42:38.122609Z","iopub.execute_input":"2024-11-29T14:42:38.123009Z","iopub.status.idle":"2024-11-29T14:42:38.132242Z","shell.execute_reply.started":"2024-11-29T14:42:38.122972Z","shell.execute_reply":"2024-11-29T14:42:38.131538Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T14:42:38.133111Z","iopub.execute_input":"2024-11-29T14:42:38.133348Z","iopub.status.idle":"2024-11-29T14:42:38.147297Z","shell.execute_reply.started":"2024-11-29T14:42:38.133324Z","shell.execute_reply":"2024-11-29T14:42:38.146478Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"hchang/t5-small-finetuned-xsum\")\ntokenizer.save_pretrained(\"hchang/t5-small-finetuned-xsum\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T14:42:38.148257Z","iopub.execute_input":"2024-11-29T14:42:38.148499Z","iopub.status.idle":"2024-11-29T14:42:38.158443Z","shell.execute_reply.started":"2024-11-29T14:42:38.148476Z","shell.execute_reply":"2024-11-29T14:42:38.157801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n\ntokenizer_finetuned = AutoTokenizer.from_pretrained(\"hchang/t5-small-finetuned-xsum\")\nmodel_finetuned = AutoModelForSeq2SeqLM.from_pretrained(\"hchang/t5-small-finetuned-xsum\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T07:04:56.673198Z","iopub.execute_input":"2024-12-23T07:04:56.673871Z","iopub.status.idle":"2024-12-23T07:04:57.663770Z","shell.execute_reply.started":"2024-12-23T07:04:56.673837Z","shell.execute_reply":"2024-12-23T07:04:57.662810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#tokenizer_pretrained = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n#model_pretrained = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer_pretrained = AutoTokenizer.from_pretrained(\"hchang/t5-small-finetuned-xsum\")\nmodel_pretrained = AutoModelForSeq2SeqLM.from_pretrained(\"hchang/t5-small-finetuned-xsum\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T07:03:55.248656Z","iopub.execute_input":"2024-12-23T07:03:55.249671Z","iopub.status.idle":"2024-12-23T07:04:20.122808Z","shell.execute_reply.started":"2024-12-23T07:03:55.249634Z","shell.execute_reply":"2024-12-23T07:04:20.121955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text = '''The three-day extravaganza of farming, food and family fun celebrates many aspects of agricultural life. \nThe Balmoral Show is run by the Royal Ulster Agricultural Society (RUAS) and dates back 148 years. \nLast year, it attracted more than 90,000 visitors to its recently-adopted home outside Lisburn in County Antrim. \nIt was traditionally staged at the RUAS's headquarters in south Belfast, but the show moved to a larger venue on the site of the former Maze prison in 2013. \nThe Maze venue, re-named Balmoral Park, is now hosting the show for the fourth consecutive year. \nThe 2016 event coincides with Northern Ireland's Year of Food and Drink, and local produce features prominently in the exhibitions. \nOne of this year's highlights is an \"edible garden\", in which visitors can see their food growing in the ground before it gets to their plates. \nThe aim of the garden is to encourage people to grow their own food at home. The event will also showcase the best of local livestock, with prized pigs, cattle, poultry and ponies all lining up in bid to be the stars of the show. \nTheir owners will also get a chance to shine, with horse riding and show jumping displays along with sheep shearing competitions and awards for the best livestock breeders and handlers. \nFor younger visitors, there is a family fun area hosting displays from the Northern Ireland School of Falconry as well as a gun dog skills demonstration and a performance from balloon artist Bruce Airhead. \nBBC News NI are covering the event live on social media on Wednesday on Twitter at @BBCNewsNI, on Snapchat at bbcnewsni, and on BBC Newsline's Facebook page.'''\ninputs = tokenizer_finetuned(text, return_tensors=\"pt\").input_ids\noutputs = model_finetuned.generate(inputs)\nprint(\"generate: \", tokenizer_finetuned.decode(outputs[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T07:05:08.719939Z","iopub.execute_input":"2024-12-23T07:05:08.720763Z","iopub.status.idle":"2024-12-23T07:05:11.623884Z","shell.execute_reply.started":"2024-12-23T07:05:08.720713Z","shell.execute_reply":"2024-12-23T07:05:11.622953Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inputs = tokenizer_pretrained(text, return_tensors=\"pt\").input_ids\noutputs = model_pretrained.generate(inputs)\nprint(\"generate: \", tokenizer_pretrained.decode(outputs[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T14:44:53.379312Z","iopub.execute_input":"2024-11-29T14:44:53.379895Z","iopub.status.idle":"2024-11-29T14:44:53.886209Z","shell.execute_reply.started":"2024-11-29T14:44:53.379859Z","shell.execute_reply":"2024-11-29T14:44:53.885238Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install rouge-score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T14:45:19.031765Z","iopub.execute_input":"2024-11-29T14:45:19.032441Z","iopub.status.idle":"2024-11-29T14:45:30.147557Z","shell.execute_reply.started":"2024-11-29T14:45:19.032407Z","shell.execute_reply":"2024-11-29T14:45:30.146452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom rouge_score import rouge_scorer\nimport torch\n\ndef validate_model(model, tokenizer, dataset, max_input_length=512, max_target_length=128):\n    \"\"\"\n    Validate the performance of the model on a validation dataset.\n\n    Args:\n        model: The summarization model (pre-finetuned or fine-tuned).\n        tokenizer: The tokenizer associated with the model.\n        dataset: The validation dataset containing 'document' and 'summary' fields.\n        max_input_length: Maximum input length for tokenization.\n        max_target_length: Maximum output length for summaries.\n\n    Returns:\n        A dictionary containing Rouge scores.\n    \"\"\"\n    model.eval()  # Set the model to evaluation mode\n    predictions = []\n    references = []\n\n    # Initialize a Rouge scorer\n    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n\n    with torch.no_grad():\n        for example in dataset:\n            # Tokenize the input document\n            inputs = tokenizer(\n                example[\"document\"],\n                max_length=max_input_length,\n                truncation=True,\n                return_tensors=\"pt\",\n                padding=\"max_length\",\n            ).input_ids.to(model.device)\n\n            # Generate a summary\n            outputs = model.generate(inputs, max_length=max_target_length, num_beams=4, early_stopping=True)\n            \n            # Decode the generated summary\n            generated_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n            predictions.append(generated_summary)\n\n            # Add the reference summary\n            references.append(example[\"summary\"])\n\n    # Compute aggregate Rouge scores\n    rouge1, rouge2, rougeL = 0, 0, 0\n    for pred, ref in zip(predictions, references):\n        scores = scorer.score(ref, pred)\n        rouge1 += scores[\"rouge1\"].fmeasure\n        rouge2 += scores[\"rouge2\"].fmeasure\n        rougeL += scores[\"rougeL\"].fmeasure\n\n    # Average the scores\n    total = len(predictions)\n    return {\n        \"rouge-1\": rouge1 / total,\n        \"rouge-2\": rouge2 / total,\n        \"rouge-L\": rougeL / total,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T14:49:38.378417Z","iopub.execute_input":"2024-11-29T14:49:38.379135Z","iopub.status.idle":"2024-11-29T14:49:39.400824Z","shell.execute_reply.started":"2024-11-29T14:49:38.379099Z","shell.execute_reply":"2024-11-29T14:49:39.400127Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"validation_data = ds[\"validation\"].select(range(1000))\n\n# Validate the model\nmetrics = validate_model(model_pretrained, tokenizer_pretrained, validation_data)\nprint(\"Validation Metrics:\", metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T14:49:42.666730Z","iopub.execute_input":"2024-11-29T14:49:42.667458Z","iopub.status.idle":"2024-11-29T14:52:42.574206Z","shell.execute_reply.started":"2024-11-29T14:49:42.667423Z","shell.execute_reply":"2024-11-29T14:52:42.573288Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#metrics_2 = validate_model(model_finetuned, tokenizer_finetuned, validation_data)\n#print(\"Validation Metrics:\", metrics_2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T14:55:09.961777Z","iopub.execute_input":"2024-11-29T14:55:09.962160Z","iopub.status.idle":"2024-11-29T14:58:10.464408Z","shell.execute_reply.started":"2024-11-29T14:55:09.962129Z","shell.execute_reply":"2024-11-29T14:58:10.463489Z"}},"outputs":[],"execution_count":null}]}